# Optimization for Data Science Course 

This course was taught by A. Gramfort (Inria) and R.Gower (Telecom ParisTech)

The pratical work consisted in :
* Lab 1 : First order methods on regression models with proximal gradient descent (PGD) and accelerated proximal gradient descent (APGD)

* Lab 2 : Logistic and linear regression with deterministic and stochastic first order methods in which we implemented 

    * Batch (deterministic) methods : Gradient Descent, Accelerated Gradient Descent and L-BFGS
    
    * Stochastic algorithm : Stochastic Gradient Descent, Stochastic Averaged Descent, Stochastic Variance Reduced Gradient
    
* Lab 3 : Proximal, cyclic and greedy coordinate descent

* Lab 4 : quasi-Newton methods 

* Project : Optimization strategies for Rank-Support Vector Machiines (SVM)

These works were done in pairs of student. 